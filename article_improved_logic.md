# Эволюция логики: Как мы улучшили векторную модель для борьбы со спамом

В первой версии нашей системы `Redis8 Spam Guard` мы использовали гибридный подход к векторизации постов. Вектор, представляющий каждый пост, состоял из двух частей:

1.  **Текстовый эмбеддинг (384 измерения):** Смысловое представление заголовка и описания.
2.  **Числовые признаки (5 измерений):** Метаданные поста, включая `reading_time`, `reactions_count`, `comments_count`, `user_followers` и `tags_count`.

Итоговый вектор имел размерность 389. На этапе обучения эта модель показывала себя хорошо, так как она училась на исторических данных, где у постов уже была накопленная статистика вовлеченности.

## Проблема: Логический парадокс при работе в реальном времени

В ходе анализа мы обнаружили фундаментальную проблему в этом подходе, которая проявлялась при классификации **новых** постов.

**Суть проблемы:** Наша система создана, чтобы реагировать на спам **мгновенно**, в момент его появления. У нового поста по определению еще нет ни реакций, ни комментариев. Его `reactions_count` и `comments_count` всегда равны нулю.

Когда мы создавали вектор для такого поста, нулевые значения в компонентах вовлеченности делали его математически "ближе" к тем векторам из обучающей выборки, у которых тоже была низкая вовлеченность. А это, как правило, и были спам-посты.

Получался парадокс: система была излишне подозрительной к **любому** новому посту, потому что его "профиль вовлеченности" был похож на спам. Мы сравнивали "яблоки" (новые посты без истории) с "апельсинами" (старыми постами с историей).

## Решение: Разделение логики маркировки и векторизации

Ключевая идея по улучшению системы заключается в том, чтобы разделить процесс принятия решения о метке "спам/не спам" и процесс создания векторного представления поста.

### 1. Этап обучения: Интеллектуальная маркировка

Мы по-прежнему используем эвристики, которые анализируют **все** доступные данные о посте, включая вовлеченность. Это позволяет нам с высокой точностью присвоить историческим данным метку `is_spam = True` или `is_spam = False`. Этот этап — "работа учителя", который использует всю полноту информации для создания качественного обучающего датасета.

### 2. Этап векторизации: "Чистый" вектор

А вот в сам вектор, который мы сохраняем в Redis, мы теперь включаем **только те признаки, которые известны в момент создания поста**. Мы **исключили** из него `reactions_count` и `comments_count`.

**Старый вектор (389 измерений):**
`[Текст (384), Время чтения, **Реакции**, **Комментарии**, Подписчики, Кол-во тегов]`

**Новый, улучшенный вектор (387 измерений):**
`[Текст (384), Время чтения, Подписчики, Кол-во тегов]`

## Преимущества нового подхода

1.  **Корректное сравнение:** Теперь вектор нового поста сравнивается с векторами из обучающей выборки по одинаковым, "честным" параметрам. Модель фокусируется на **содержании** поста и **репутации автора**, а не на вовлеченности, которой еще не может быть.
2.  **Устранение предвзятости:** Мы убрали предвзятость системы по отношению к новым постам. Теперь хороший пост от нового автора не будет ошибочно классифицирован как спам только потому, что у него 0 лайков.
3.  **Более робастная модель:** Система вынуждена учиться находить спам по его сути (ключевые слова, структура текста, подозрительные теги), а не по косвенным признакам. Это делает модель более устойчивой и точной.

Этот рефакторинг логики — отличный пример того, как критический анализ работы системы может привести к значительному улучшению ее архитектуры и надежности, не требуя при этом сложных изменений в коде.

## Финальный рывок: Создание синтетического датасета

После внедрения улучшенной логики мы столкнулись с новой проблемой: несбалансированность данных. Данные с dev.to содержали очень мало реального спама. В результате модель, даже будучи архитектурно правильной, не могла эффективно обучаться — ей просто не хватало примеров "плохого" поведения. Метрики `precision` и `recall` оставались на нуле.

Решение было очевидным: если в реальных данных нет спама, мы должны создать его сами.

Мы сгенерировали файл `spam_dataset.json`, содержащий 50 разнообразных примеров явного спама:

-   Предложения быстрого заработка и крипто-схемы.
-   Фишинговые ссылки и поддельные уведомления безопасности.
-   Продажа SEO-услуг, накрутка подписчиков.
-   Сомнительные курсы, чудо-товары и многое другое.

Затем мы доработали скрипт обучения, чтобы он объединял "чистые" данные с dev.to с нашим "грязным" спам-датасетом. Это позволило создать сбалансированную выборку, на которой модель смогла наконец-то раскрыть свой потенциал.

## Результат: Работающая и надежная модель

После обучения на новом, сбалансированном датасете мы получили следующие метрики:

-   **Accuracy (Точность):** ~94%
-   **Precision (Прецизионность):** **1.0** — идеальный результат! Это означает, что модель не совершила **ни одного ложного срабатывания**, назвав хороший пост спамом.
-   **Recall (Полнота):** **~30%** — модель успешно обнаружила и классифицировала треть всего спама в тестовой выборке. Это огромный скачок с нуля и отличная отправная точка для дальнейших улучшений.

Полученная модель является "осторожной": она предпочитает пропустить спам, чем заблокировать легитимный контент. Это критически важное свойство для любой системы модерации.

В итоге, пройдя путь от анализа и исправления архитектурных недостатков до обогащения данных, мы создали по-настоящему работающую и надежную систему для борьбы со спамом.
