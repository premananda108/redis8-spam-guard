'''# Протокол Устранения Неполадок и Доработок

Этот документ описывает шаги, предпринятые для диагностики, устранения проблем и последующей доработки приложения Spam Guard.

## Часть 1: Первоначальная Настройка и Обучение (25.07.2025)

...

## Часть 2: Улучшения Веб-интерфейса и Отказоустойчивость (26.07.2025)

...

### 2.3. Реализация сбора и отображения статистики

- **Задача:** Заменить статические данные в разделе статистики на реальные, получаемые из Redis.
- **Решение:**
    1. **Сбор статистики:** Эндпоинт `/classify` был доработан для атомарного инкрементирования счетчиков `stats:total_classified` и `stats:spam_detected` в Redis после каждой классификации.
    2. **Получение статистики:** Эндпоинт `/stats` был переписан для чтения этих счетчиков из Redis. В случае недоступности Redis он возвращает нули.
    3. **Отображение точности:** В `/stats` добавлено чтение последнего показателя `accuracy` из файла `training_results.json`, чтобы в интерфейсе всегда была актуальная информация о качестве модели.
    4. **Обновление интерфейса:** Фронтенд был обновлен для корректного отображения всех новых полей статистики.

### 2.4. Исправление логики получения количества подписчиков

- **Проблема:** Несмотря на предыдущие исправления, приложение по-прежнему для всех статей показывало признак "Low follower count".
- **Расследование:**
    1. **Первоначальная гипотеза:** API `dev.to` не возвращает информацию о подписчиках в общем списке статей. Это подтвердилось.
    2. **Первая попытка исправления:** Был добавлен дополнительный запрос к API `dev.to/api/users/{user_id}` для получения полных данных о пользователе. Однако ошибка сохранилась.
    3. **Вторая попытка и обнаружение бага:** Было выявлено, что данные о подписчиках, полученные в `vectorize_post`, не передавались в `predict` для эвристического анализа, что приводило к неверной оценке.
    4. **Третья попытка и обнаружение коренной причины:** После исправления предыдущего бага ошибка все равно осталась. Финальный анализ показал, что в коде использовалось неверное имя поля для ID пользователя (`user_id` вместо `id`), из-за чего запрос к API пользователей никогда не выполнялся.
- **Решение (финальное):**
    1. В функции `create_features` исправлено имя поля на `post.user.get('id')`.
    2. В `vectorize_post` добавлена логика для корректной обработки ситуации, когда данные о подписчиках получить не удалось (используется значение `-1`).
    3. В `get_spam_indicators` добавлена проверка, чтобы причина "Low follower count" отображалась только в том случае, если данные о подписчиках были успешно загружены и их действительно мало.
    4. Логика передачи данных между `vectorize_post` и `predict` была исправлена, чтобы гарантировать консистентность данных при создании вектора и генерации текстовых причин.

## Часть 3: Отладка и улучшение процесса обучения (26.07.2025)

### 3.1. Улучшение эвристической классификации

- **Проблема:** В режиме без Redis все посты получали одинаковую, нереалистичную оценку уверенности (60% или 65%).
- **Решение:** Внедрена более гранулированная логика в `predict`:
    - 0 индикаторов: Не спам (уверенность 80%)
    - 1 индикатор: Не спам (уверенность 60%)
    - 2 индикатора: Спам (уверенность 70%)
    - 3+ индикатора: Спам (уверенность 90%)
- **Результат:** Оценка стала более динамичной и правдоподобной при работе без Redis.

### 3.2. Исправление ошибок в скрипте обучения (`train_model.py`)

- **Проблема 1:** Скрипт обучения мог запускаться без подключения к Redis, что делало его работу бессмысленной.
- **Решение 1:** В начало `train_model.py` добавлена проверка на доступность Redis. Если соединения нет, скрипт завершает работу с ошибкой.

- **Проблема 2:** Скрипт падал, так как не мог создать индекс в Redis, ожидая сообщение `Unknown Index name`, в то время как Redis возвращал `no such index`.
- **Решение 2:** В `main.py` в процедуру создания индекса добавлена проверка на оба варианта текста ошибки.

- **Проблема 3:** Модель `SentenceTransformer` загружалась в память дважды, что замедляло запуск и расходовало ресурсы.
- **Решение 3:** `train_model.py` был изменен, чтобы повторно использовать экземпляр классификатора, созданный в `main.py`, вместо создания нового.

- **Проблема 4:** Скрипт падал с ошибкой `'tuple' object has no attribute 'tobytes'`.
- **Решение 4:** В `train_model.py` исправлена логика вызова `vectorize_post`, чтобы корректно обрабатывать возвращаемый кортеж (вектор и признаки).

### 3.3. Отладка логики отображения причин классификации

- **Проблема:** После успешного обучения модель для всех постов показывала причину `Heuristic analysis based on post content`, вместо более информативной `Similar to known spam posts (via Redis)`.
- **Расследование:**
    1. **Гипотеза:** Логика в `predict` была неверной. Она показывала причину на основе Redis только в том случае, если не было найдено ни одного другого эвристического индикатора.
    2. **Попытка исправления:** Логика была изменена, чтобы причина на основе Redis всегда была основной, а остальные индикаторы добавлялись к ней.
    3. **Результат:** Проблема не решилась. Это указывает на то, что основной блок кода, использующий Redis, по какой-то причине не выполняется.
    4. **Следующий шаг:** Для дальнейшей диагностики в `predict` было добавлено логирование, чтобы отследить, сколько похожих постов возвращает Redis. Это поможет понять, почему основной блок кода игнорируется.
- **Финальное расследование и решение:**
    1. **Диагностика Redis:** Был создан и запущен диагностический скрипт (`test_redis_index.py`) для проверки состояния индекса `post_vectors` напрямую в Redis. Проверка показала, что индекс существует, содержит 962 документа и не имеет ошибок. Это подтвердило, что проблема не в данных, а в коде, который их читает.
    2. **Обнаружение коренной причины:** Анализ функции `find_similar_posts` в `main.py` выявил, что код, отвечающий за обработку ответа от Redis, был написан с ошибкой. Он неправильно разбирал структуру возвращаемых данных, из-за чего всегда возвращал пустой список, даже если похожие посты были найдены.
    3. **Решение:** Дефектный блок кода для парсинга результатов был полностью заменен на корректную реализацию, которая правильно обрабатывает сложную структуру ответа от команды `FT.SEARCH`.
- **Результат:** После исправления приложение начало корректно находить похожие посты в Redis и отображать основную причину классификации как `Similar to known spam posts (via Redis)` или `Similar to legitimate posts (via Redis)`, как и ожидалось.

## Часть 4: Добавление интерактивной проверки (26.07.2025)

### 4.1. Реализация формы для ручной проверки постов

- **Задача:** Добавить в веб-интерфейс возможность вручную вводить данные поста и получать его классификацию без необходимости искать этот пост в общей ленте.
- **Решение:**
    1.  **Модификация интерфейса:** В `main.py` была изменена HTML-структура. Страница была разделена на две колонки: основной контент слева и боковая панель (sidebar) справа.
    2.  **Добавление формы:** В боковую панель добавлена HTML-форма "Manual Post Check" с полями для всех необходимых атрибутов поста (заголовок, описание, теги, реакции, комментарии, время чтения, количество подписчиков автора).
    3.  **Реализация логики на фронтенде:**
        *   Написана новая JavaScript-функция `performManualCheck()`.
        *   Эта функция собирает данные из формы, формирует из них объект `postData`, соответствующий Pydantic-модели `DevToPost`.
        *   Для полей, которых нет в форме (ID поста, ID пользователя), генерируются случайные значения, так как они необходимы для валидации на бэкенде.
        *   Функция отправляет запрос на **существующий** эндпоинт `/classify` методом POST. Это позволило избежать написания нового кода на бэкенде.
        *   Полученный результат (диагноз поста) динамически отображается на странице прямо под формой.
- **Результат:** Приложение стало значительно более наглядным и интерактивным. Пользователь может мгновенно тестировать различные сценарии и видеть, как система реагирует на те или иные признаки спама, не сохраняя эти тестовые посты в базу данных.

## Часть 5: Оптимизация загрузки модели (27.07.2025)

### 5.1. Устранение двойной загрузки модели SentenceTransformer

- **Проблема:** При запуске приложения с помощью `python main.py` в консоли дважды появлялось сообщение `INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2`. Это указывало на то, что модель загружается в память дважды, что замедляло запуск и излишне расходовало ресурсы.
- **Расследование:**
    1. **Первоначальная гипотеза:** Проблема была в том, что при запуске обучения создавался новый экземпляр `RedisVectorClassifier`. Были внесены изменения для передачи существующего экземпляра в функцию обучения.
    2. **Результат:** Проблема не решилась. Это указывало на более глубокую проблему, связанную с процессом запуска.
    3. **Обнаружение коренной причины:** Было установлено, что двойная загрузка вызвана тем, как `uvicorn` обрабатывает запуск приложения. При запуске через `python main.py` скрипт выполняется один раз, а затем `uvicorn` запускает рабочий процесс, который импортирует и выполняет скрипт еще раз.
- **Решение:**
    1. **Реализация паттерна Синглтон (Singleton):** В `core.py` был создан класс `ModelSingleton`.
    2. **Ленивая загрузка:** Этот класс загружает модель `SentenceTransformer` только один раз при первом вызове метода `get_instance()`. Все последующие вызовы возвращают уже существующий в памяти экземпляр.
    3. **Интеграция:** В конструкторе `RedisVectorClassifier` прямой вызов `SentenceTransformer()` был заменен на `ModelSingleton.get_instance()`.
- **Результат:** Проблема двойной загрузки была полностью устранена. Теперь модель гарантированно загружается в память только один раз, независимо от способа запуска приложения, что повысило эффективность и скорость запуска.
'''